\documentclass[12pt]{article}

\usepackage{amsmath}
\usepackage[super]{nth}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{gensymb}

\pagenumbering{arabic}

\begin{document}
\title{List of algoritms used in graphical analysis}
\date{December 06, 2016}
\author{Rafael De Smet}

\maketitle

\section{Algorithms}
\subsection{Edge Detection}

Edge detection algorithms all use what are called convolution kernels. A kernel in image processing is a small matrix used to apply effects to an image, such as blurring, outlining. Here we will see kernels used for edge detection only. Listed below are six of the best and most used algorithms.

\begin{itemize}
	\item Sobel 
	\item Frei-Chen
	\item Prewitt
	\item Roberts Cross
	\item LoG
	\item Scharr
\end{itemize}

\subsubsection{Convolution kernel}
Since all the algorithms are based on the mathematical principle of convolution, some explanation of these convolution kernels is in order. 

Convolution is the technique of mutiplying together two arrays of different size but of the same dimensionality. One of the two arrays used in the calculation is the numerical representation of the image (pixels) on which we want to perform the edge detection algorithm. The second array is called the kernel and is usually much smaller (but in the same dimensionality).

Each pixel of the image is added to its local neighbours, weighted by the kernel. This produces a new image. If the kernel is chosen wisely, we get all the edges found in the image.

Mathematically we can write the convolution as follows, with $O$ the output image, $I$ the input image and $K$ the kernel:

\begin{equation}
O(i, j) =  \sum\limits_{k=1}^m\sum\limits_{l=1}^n I(i + k - 1, j + l - 1)K(k,l)
\end{equation}

\subsubsection{Sobel}
 This algorithm performs a 2D spatial gradient measurement and finds regions of 'high spatial frequency' or edges. It uses two 3x3 kernels, one kernel is used for the vertical edges and the other for the horizontal edges in the image. These two kernels can be applied seperately and the afterwards combined together to find the absolute magnitude of the gradient.
 \newline
 \newline
 The horizontal kernel: 
 $\begin{vmatrix}
	-1 & 0 & +1\\
	-2 & 0 & +2\\
	-1 & 0 & +1\\
\end{vmatrix}$
and the vertical kernel:
$\begin{vmatrix}
	+1 & +2 & +1\\
	0 & 0 & 0\\
	-1 & -2 & -1\\
\end{vmatrix}$

\subsubsection{Frei-Chen}
 The Frei-Chen algorithm also uses 3x3 kernels, but this time there are nine different convolution kernels. The four first matrices, G1, G2, G3, G4, are used for edges, the next four are used for lines and the last is used to compute averages. 
\newline
\newline
 $G_1$ = $\frac{1}{2\sqrt2}$ $\begin{vmatrix}
	1 & \sqrt2 & 1\\
	0 & 0 & 0\\
	-1 & -\sqrt2 & -1\\
\end{vmatrix}$\hspace{5mm}
$G_2$ = $\frac{1}{2\sqrt2}$$\begin{vmatrix}
	1 & 0 & -1\\
	\sqrt2 & 0 & -\sqrt2\\
	1 & 0 & -1\\
\end{vmatrix}$\hspace{5mm}
$G_3$ = $\frac{1}{2\sqrt2}$$\begin{vmatrix}
	0 & -1 & \sqrt2\\
	1 & 0 & -1\\
	-\sqrt2 & 1 & 0\\
\end{vmatrix}$\hspace{5mm}
\newline
$G_4$ = $\frac{1}{2\sqrt2}$$\begin{vmatrix}
	\sqrt2 & -1 & 0\\
	-1 & 0 & 1\\
	0 & 1 & -\sqrt2\\
\end{vmatrix}$\hspace{5mm}
$G_5$ = $\frac{1}{2}$$\begin{vmatrix}
	0 & 1 & 0\\
	-1 & 0 & -1\\
	0 & 1 & 0\\
\end{vmatrix}$\hspace{10mm}
$G_6$ = $\frac{1}{2}$$\begin{vmatrix}
	-1 & 0 & 1\\
	0 & 0 & 0\\
	1 & 0 & -1\\
\end{vmatrix}$\hspace{5mm}
\newline
$G_7$ = $\frac{1}{6}$$\begin{vmatrix}
	1 & -2 & 1\\
	-2 & 4 & -2\\
	1 & -2 & 1\\
\end{vmatrix}$\hspace{13mm}
$G_8$ = $\frac{1}{6}$$\begin{vmatrix}
	-2 & 1 & -2\\
	1 & 4 & 1\\
	-2 & 1 & -2\\
\end{vmatrix}$\hspace{11mm}
$G_9$ = $\frac{1}{3}$$\begin{vmatrix}
	1 & 1 & 1\\
	1 & 1 & 1\\
	1 & 1 & 1\\
\end{vmatrix}$\hspace{5mm}

\subsubsection{Prewitt}
This algorithm is very similar to the Sobel and Frei-Chen algorithms. Again, two kernels are used, one for the horizontal and one for the vertical edges. Afterwards, they are combined together to get all the edges in the image.
\newline
\newline
This time the kernels are considerably simpler
\newline
\newline
Horizontal filter = $\begin{vmatrix}
	1 & 1 & 1\\
	0 & 0 & 0\\
	-1 & -1 & -1\\
\end{vmatrix}$\hspace{11mm}
Vertical filter = $\begin{vmatrix}
	-1 & 0 & 1\\
	-1 & 0 & 1\\
	-1 & 0 & 1\\
\end{vmatrix}$
\newline
\newline
Because the kernels are simpler, the result is not so accurate when compared to the other algorithms.

\subsubsection{Roberts Cross}
This algorithm uses even simpler kernels than Prewitt does. This time we use two 2x2 kernels. These kernels correspond to the edges running at 45Â° to the pixel grid, one for each of the two perpendicular orientations.
\newline
\newline
Horizontal filter = $\begin{vmatrix}
	1 & 0 \\
	0 & -1 \\
\end{vmatrix}$\hspace{11mm}
Vertical filter = $\begin{vmatrix}
	0 & 1\\
	-1 & 0\\
\end{vmatrix}$

\subsubsection{LoG}
This algorithm combines two methods, the Gaussian filtering method \footnote{The Gaussian filter is used to blur images and remove noise and detail.} and the Laplacian method for edge detection\footnote{This method highlights regions in the image of rapid intensity change, so it is useful for edge detection.}. Hence the name "Laplacian of Gaussian" (LoG)
\newline
\newline
The edge points of an image are detected by finding the zero crossings of the \nth{2} derivative of the image intensity. Because the \nth{2} derivative is very sensitive to noise, which could give us bad results, the Gaussian filter is used to clear the noise from the image. 
\newpage
The R library OpenImageR\footnote{https://cran.r-project.org/web/packages/OpenImageR/OpenImageR.pdf} uses the following LoG mask.
\newline
\newline
LoG mask = $\begin{vmatrix}
	1 & 1 & 1\\
	1 & -8 & 1\\
	1 & 1 & 1\\
\end{vmatrix}$

\subsubsection{Scharr}
This algorithm is an extension of the Sobel algorithm. Although the Sobel kernels are very good, they do not have perfect rotational symmetry. This is what the Scharr kernels try to optimize this property.
\newline
\newline
The most frequently used kernels are the following:
\newline
\newline
Horizontal filter = $\begin{vmatrix}
	3 & 10 & 3\\
	0 & 0 & 0\\
	-3 & -10 & -3\\
\end{vmatrix}$\hspace{11mm}
Vertical filter = $\begin{vmatrix}
	3 & 0 & -3\\
	10 & 0 & -10\\
	3 & 0 & -3\\
\end{vmatrix}$\hspace{5mm}

\subsection{Color Analysis}
Only edge detection algorithms are not going to be sufficient to get enough data from the image to form a musical interpretation. We will need some form of color analysis. This section proposes some algorithms and methods we can use to obtain information about the colors of the image.

\subsubsection{RGB}
This is the most common representation of color on a computer. Each pixel is described using three values, the amount of red (R), green (G) and blue (B) it has. Using these values we can count how many pixels in the image are dominantly red, green or blue. When we're going to translate the image data into musical patterns, we can match each color to another kind of music (happy, sad, etc...)
 
\subsubsection{HSV}
HSV, sometimes called HSB, is another representation of a pixel. This time we use the hue (H), the saturation (S) and the brightness or value (B or V) to describe the pixel. Where the RGB model consists of three values indicating the amounts of a certain color each pixel has, the HSV model consists of three independent components. 
\newline
\newline
First we have the hue, which is basically the color. Here the color is represented using a circle with all the colors on it. So this means the value of this component is the degrees of the angle we have to make on the circle to get this color.  
\newline
\newline
The saturation indicates the fullness of the color. This value is expressed in a percentage, with 0\% a gray, flat color and 100\% is a full, rich color.
\newline
\newline
The value or brightness indicates the lightness of the color and is als expressed in a percentage, 0\% is black and 100\% is white.
\newline
\newline
This representation will be used in combination with the RGB model in the translation into the musical patterns.
 
\subsubsection{CMYK}
CMYK is another representation of color, based on the mixing of four colors, cyan (C), magenta (M), yellow (Y) and key (K, black). This model is used frequently with printing.
\newline
When combined, the data from the three models can be very accurate to use in the translation.

\subsubsection{Black And White Balance}
During the image analysis we will convert the image to a grayscale image, so we can determine the amount of white and black in it. Using the RGB model, this is an easy process. Black in the RGB model is (0,0,0) and white is (255,255,255). So we can simply count the amount of pixels that are very close to those two values and we know the amount of black and white pixels in the image.
\newline
Analogous to this we can count every gray pixel in the image, by finding every pixel where the RGB values are exactly the same.

\end{document}